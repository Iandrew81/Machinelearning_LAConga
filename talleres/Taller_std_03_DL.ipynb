{"cells":[{"cell_type":"markdown","metadata":{"id":"uGUEZRJxrUfA"},"source":["<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/banner_IA.png\"  width=\"1000px\" height=\"200px\">\n","\n","# **Taller 03:  Deep Learning**\n","\n","## **Outline**\n","\n","1. [Ejercicio 1.](#eje1)\n","2. [Ejercicio 2.](#eje2)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1660365916303,"user":{"displayName":"Andres Villares","userId":"14230366839958215789"},"user_tz":300},"id":"Eyzd86nGrLkv","outputId":"80255e29-8e9b-486c-da81-03fdadfb69df"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nPut your student ID here\\n\\nExample: student_id =  '2152145'\\n\""]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["#@title **Execute this cell**\n","#@markdown Please include your student id\n","import sys\n","import inspect\n","\n","group_id = \"ML-20221-Laconga\" #@param {type:\"string\"}\n","assignment_id = group_id +'.taller_deep_learning'\n","student_id = \"2022146\" #@param {type:\"string\"}\n","\"\"\"\n","Put your student ID here\n","\n","Example: student_id =  '2152145'\n","\"\"\" "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vF9FTR5Atp70"},"outputs":[],"source":[" #@title **Execute this cell**\n","#@markdown **UTILS**\n","#@markdown Please dont modify any line in this cell\n","\n","import os\n","import json\n","import requests\n","from collections import namedtuple\n","\n","\n","Config = namedtuple('Config', ['server_name'])\n","config = Config(server_name='https://bivlabgrader.azurewebsites.net/api')\n","\n","\n","def check_solution_and_evaluate(assignment_id: str, student_func_str: str):\n","\n","    # Set the endpoint and payload.\n","    payload = {\n","        'func_str': student_func_str,\n","        'assignment_id': assignment_id,\n","        'student_id': student_id\n","    }\n","    endpoint_url = config.server_name + '/CheckAndEvaluateSolution'\n","    # print(endpoint_url)\n","\n","    # Make request to server with the data coming from the notebook.\n","    r = requests.post(endpoint_url, params=payload)\n","    pprint_json_response(r.json())\n","    return r\n","\n","\n","def pprint_json_response(response, indent=0):\n","    \"\"\"Pretty print the response.\"\"\"\n","    for key, value in response.items():\n","        print('\\t' * indent + str(key.capitalize()))\n","\n","        # If dictionary, do a recurrent call.\n","        if isinstance(value, dict):\n","            pprint_json_response(value, indent + 1)\n","        else:\n","            # Enumerate elements if list.\n","            if isinstance(value, list):\n","                if len(value) == 1:\n","                    print('\\t' * (indent + 1) + str(value[0]))\n","                else:\n","                    for i, e in enumerate(value, start=1):\n","                        print('\\t' * (indent + 1) + f'{i}. {e}')\n","            else:\n","                print('\\t' * (indent + 1) + str(value))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"KApJf0bWmI9A"},"outputs":[],"source":["#@title **Imports**\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"id":"Bm8Lc06xtys2"},"source":["---\n","# **Ejercicio 1**  <a name=\"eje1\"></a>\n","---"]},{"cell_type":"markdown","metadata":{"id":"hDKqbEeFmyrt"},"source":["Vamos a desarrollar una DNN para resolver un problema de **clasificación**. Recuerde que en un problema de clasificación, la última capa debe tener una cierta cantidad de neuronas y una cierta función de activación. Implemente una función que:\n","\n","- Utilice los datos de un dataset sintético _make_blobs_ que está incluido en [`sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs). <br>Utilice la información de tamaño de las caracteristicas para definir las características de la capa inicial.\n","\n","- Mediante la función `train_test_split` tome el 80% de los datos para entrenar y la cantidad restante para testing, **desactivando** la opción shuffle.\n","\n","- Cree una red neuronal que reciba en la capa de entrada **todas las caracteristicas del dataset** y además tenga las siguientes capas intermedias (ocultas):\n","\n"," - Dos (2) capas de 512 neuronas\n"," - Dos (2) capas de 256 neuronas\n"," - Dos (2) capas de 128 neuronas\n"," - Dos (2) capas de 64 neuronas\n","\n","   Y todas ellas con función de activación `relu`\n","\n","- La red neuronal debe ser entrenada con un optimizador `SGD`, `epochs`=10,  `batch_size`=16, regla de minimización (loss): `'sparse_categorical_crossentropy'` y métrica de evaluación `'accuracy'`\n","\n","- Devuelva el historial del entrenamiento `history`\n","- Devuelva el resultado del comando `evaluate` en la variable `scores`\n","- Devuelva el resultado del comando `predict` en la variable `yest`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zUAp-IKtCIv5"},"outputs":[],"source":["#@title **code student**\n","#@markdown No modifique las dos últimas lineas\n","\n","def function_t06_1(data, data_y):\n","    #libraries\n","    import numpy as np\n","    import tensorflow as tf\n","    from tensorflow import keras\n","    from sklearn.model_selection import train_test_split\n","    from sklearn.datasets import make_blobs\n","    \n","    \"\"\"Put your code here\"\"\"\n","\n","    tf.random.set_seed(21)\n","    np.random.seed(21)\n","\n","    X, y = make_blobs(n_samples= 100, n_features=2, centers=2)\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n","    nclasses = 2\n","\n","    dnn1 = tf.keras.Sequential([ \n","        tf.keras.layers.Dense(512, activation='relu',input_shape=[X_train.shape[1]]),\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        tf.keras.layers.Dense(256, activation='relu'),\n","        tf.keras.layers.Dense(256, activation='relu'),\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dense(nclasses, activation='sigmoid')\n","    ])\n","\n","    dnn1.summary()     \n","\n","    y_train_ohe = tf.keras.utils.to_categorical(y_train, num_classes=nclasses)\n","    y_test_ohe = tf.keras.utils.to_categorical(y_test, num_classes=nclasses)\n","\n","    dnn1.compile(optimizer=tf.keras.optimizers.SGD(), \n","              loss='sparse_categorical_crossentropyy',\n","              metrics=['accuracy'])\n","    history = dnn1.fit(X_train,\n","          y_train_ohe,\n","          epochs=10,\n","          batch_size=16,\n","          validation_data=(X_test, y_test_ohe))\n","    scores = dnn1.evaluate(X_test, y_test)\n","    yest = dnn1.predict(X_test)\n","    \n","    return history, scores, yest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2388,"status":"error","timestamp":1660366505303,"user":{"displayName":"Andres Villares","userId":"14230366839958215789"},"user_tz":300},"id":"xIeHhkQzt9cA","outputId":"e0c67a9a-1253-432c-a301-a1055e4b4cc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_99 (Dense)            (None, 512)               1536      \n","                                                                 \n"," dense_100 (Dense)           (None, 512)               262656    \n","                                                                 \n"," dense_101 (Dense)           (None, 256)               131328    \n","                                                                 \n"," dense_102 (Dense)           (None, 256)               65792     \n","                                                                 \n"," dense_103 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dense_104 (Dense)           (None, 128)               16512     \n","                                                                 \n"," dense_105 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dense_106 (Dense)           (None, 64)                4160      \n","                                                                 \n"," dense_107 (Dense)           (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 523,266\n","Trainable params: 523,266\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-d3660cc13e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_t06_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-54-6915dc8f5859>\u001b[0m in \u001b[0;36mfunction_t06_1\u001b[0;34m(data, data_y)\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m           validation_data=(X_test, y_test_ohe))\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0myest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 2369, in get\n        return deserialize(identifier)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 2328, in deserialize\n        printable_module_name='loss function')\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\", line 710, in deserialize_keras_object\n        f'Unknown {printable_module_name}: {object_name}. Please ensure '\n\n    ValueError: Unknown loss function: sparse_categorical_crossentropyy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"]}],"source":["#@title **send your answer**\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.datasets import make_blobs\n","import matplotlib.pyplot as plt\n","np.random.seed(21)\n","\n","c = []\n","for i in range(6):\n","  c.append([np.random.randint(5)*np.random.rand(), np.random.randint(5)*np.random.rand()])\n","\n","data, data_y = make_blobs(n_samples=2000, centers=c, n_features=13, random_state=21)\n","h, scores, ypred = function_t06_1(data, data_y)\n","\n","plt.plot(h.history['loss'], label=\"loss\")\n","plt.plot(h.history['accuracy'], label=\"accuracy\")\n","plt.legend()\n","plt.show()\n","\n","print(\"Check...\")\n","student_func_str = inspect.getsource(function_t06_1)\n","r = check_solution_and_evaluate(assignment_id, student_func_str)"]},{"cell_type":"markdown","metadata":{"id":"qAX0TE0ht81m"},"source":["---\n","# **Ejercicio 2**  <a name=\"eje2\"></a>\n","---"]},{"cell_type":"markdown","metadata":{"id":"bEc-gA1yFifN"},"source":["Vamos a desarrollar una DNN para resolver un problema de **regresión**. La principal diferencia en estas arquitecturas esta en la capa de salida: solo debemos tener una neurona sin función de activación que nos permita dar una respuesta en terminos de la escala de los datos. Implemente una función que:\n","\n","- Utilice los datos de _california_housing_ que están en [`sklearn`](https://scikit-learn.org/0.16/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing). <br>Utilice la información de tamaño de las caracteristicas para definir las características de la capa inicial.\n","\n","- Mediante la función `train_test_split` tome el 85% de los datos para entrenar y la cantidad restante para testing, **desactivando** la opción shuffle.\n","\n","- Cree una red neuronal que reciba en la capa de entrada **todas las caracteristicas del dataset** y además tenga tres capas intermedias (ocultas) de 128, 64 y 32 neuronas, respectivamente. Las activaciones para las capas intermedias deben ser tangente hiperpolica `tanh`.\n","\n","- La red neuronal debe ser entrenada con un optimizador `RMSprop`, `epochs`=5,  `batch_size`=128, regla de minimización (loss): `'mae'` y métrica de evaluación `'mse'`\n","\n","- Devuelva el historial del entrenamiento `history`\n","- Devuelva el resultado del comando `predict` en la variable `yest`\n","- Devuelva el resultado del comando `evaluate` en la variable `scores`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"executionInfo":{"elapsed":424,"status":"error","timestamp":1660363262884,"user":{"displayName":"Andres Villares","userId":"14230366839958215789"},"user_tz":300},"id":"8drR2lzoCbyJ","outputId":"ca26ef58-bc5b-4561-e52f-17b684086df3"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-a29516ea0a9b>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    None\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["#@title **code student**\n","#@markdown No modifique las dos últimas lineas\n","\n","def function_t06_2(data, data_y):\n","    #libraries\n","    import numpy as np\n","    import tensorflow as tf\n","    from tensorflow import keras\n","    from sklearn.model_selection import train_test_split\n","    from sklearn.datasets import california_housing\n","\n","    \"\"\" Put your code here. \"\"\"\n","\n","    tf.random.set_seed(21)\n","    np.random.seed(21)\n","\n","    X_train, X_test, y_train, y_test = None\n","\n","    dnnr = None([\n","          None\n","          None\n","          None\n","          None\n","          None\n","      ])\n","    dnnr.None(None, \n","                None,\n","                None)\n","    history = dnnr.None\n","    yest = dnnr.None\n","    scores = dnnr.None\n","    \n","    return history, yest, scores"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":6,"status":"error","timestamp":1660363265199,"user":{"displayName":"Andres Villares","userId":"14230366839958215789"},"user_tz":300},"id":"h5OqP96SuExg","outputId":"3fac6f15-8cf1-46a2-8ec0-eb30f5b690a8"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-051db9a069e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_t06_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'function_t06_2' is not defined"]}],"source":["#@title **send your answer**\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.datasets import fetch_california_housing\n","import matplotlib.pyplot as plt\n","\n","tf.random.set_seed(21)\n","np.random.seed(21)\n","\n","data = fetch_california_housing()[\"data\"]\n","data_y = fetch_california_housing()[\"target\"]\n","\n","h, yest, score = function_t06_2(data, data_y)\n","\n","plt.plot(h.history['loss'], label=\"loss\")\n","plt.plot(h.history['mse'], label=\"mse\")\n","plt.legend()\n","plt.show()\n","\n","print(\"Check...\")\n","student_func_str = inspect.getsource(function_t06_2)\n","r = check_solution_and_evaluate(assignment_id, student_func_str)"]},{"cell_type":"markdown","metadata":{"id":"7Eu9G3tOuO6e"},"source":["---\n","<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/bannerThanks.jpg\" alt=\"Drawing\" style=\"width:700px;\"/>"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Taller_std_03_DL.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}